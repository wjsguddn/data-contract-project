# -*- coding: utf-8 -*-
"""
Markdown â†’ Semantic JSON (ì¡°/í•´ì„¤/ì†Œì œëª© + í‘œ ë§¤í•‘ + í˜ì´ì§€ ê°„ êµ¬ë¶„ ìƒì†)
------------------------------------------------------------------------
- Vision ëª¨ë¸ í›„ì²˜ë¦¬ Markdownì„ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ JSON êµ¬ì¡°í™”
- í‘œ(| ... |) ìë™ ê°ì§€ ë° JSON ë§¤í•‘
- í˜ì´ì§€ ë„˜ì–´ê°€ë„ 'êµ¬ë¶„' ì—´(ì˜ˆ: ë°ì´í„° ê±°ë˜ ì¤‘ê°œ ê´€ë ¨)ì´ ìë™ ìƒì†ë¨
- "ì œxì¥ ..." / "â”ƒí‘œ nâ”ƒ ..." êµ¬ì¡° ì •í™•íˆ ì¸ì‹
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

# ========= ì„¤ì • =========
MD_DIR = Path(r"C:\Users\USER\Downloads\pdf-ocr-test - ë³µì‚¬ë³¸\markitdowntext\3_md_final")
PAGE_GLOB = "page-*.md"
PAGE_START = 222
PAGE_END = 224
OUT_JSON = Path(r"C:\Users\USER\Downloads\pdf-ocr-test - ë³µì‚¬ë³¸\markitdowntext\parsed_222_224_table_1.json")
# ========================

RE_H = re.compile(r"^(#{1,6})\s+(.*)\s*$")
RE_ARTICLE_H2 = re.compile(r"^ì œ\s*\d+\s*ì¡°\b")

CANON_HEADERS = ["êµ¬ë¶„", "ì£¼ìš” í•­ëª©", "í™•ì¸ì‚¬í•­", "í™•ì¸", "ê´€ë ¨ì¡°í•­"]


# ------------------------------------------------------------
# 1ï¸âƒ£ Markdown ë‚´ í‘œ íŒŒì„œ
# ------------------------------------------------------------
def parse_markdown_table(md_text: str) -> Tuple[List[Dict[str, Any]], Optional[str]]:
    """
    Markdown ë‚´ | ... | í˜•ì‹ í‘œë¥¼ íƒì§€í•´ JSONìœ¼ë¡œ ë³€í™˜.
    - í‘œ ê°„ êµ¬ë¶„ì„  ë¬´ì‹œ
    - 5ì—´ ê°•ì œ ì •ê·œí™”
    - êµ¬ë¶„, ì£¼ìš”í•­ëª©, ê´€ë ¨ì¡°í•­ ìƒì†
    """
    tables = []
    last_group_overall = None
    blocks = re.findall(r"((?:\|.*\|\n?)+)", md_text)

    for block in blocks:
        lines = [ln.strip() for ln in block.strip().splitlines() if ln.strip()]
        if not lines:
            continue

        # header & data ë¶„ë¦¬
        header = [c.strip() for c in lines[0].strip("|").split("|")]
        if len(header) != 5 or not any("êµ¬ë¶„" in h for h in header):
            header = CANON_HEADERS[:]

        rows = []
        last_group = last_item = last_ref = None

        for ln in lines[1:]:
            cells = [c.strip() for c in ln.strip("|").split("|")]
            if all(re.fullmatch(r"[-â”€â€”_]+", c) or not c for c in cells):
                continue
            if len(cells) < 5:
                cells += [""] * (5 - len(cells))
            elif len(cells) > 5:
                cells = cells[:5]

            row = dict(zip(CANON_HEADERS, cells))

            # ë¹ˆ ì¹¸ ìƒì†
            if not row["êµ¬ë¶„"]:
                row["êµ¬ë¶„"] = last_group or ""
            if not row["ì£¼ìš” í•­ëª©"]:
                row["ì£¼ìš” í•­ëª©"] = last_item or ""
            if not row["ê´€ë ¨ì¡°í•­"]:
                row["ê´€ë ¨ì¡°í•­"] = last_ref or ""

            rows.append(row)
            if row["êµ¬ë¶„"].strip():
                last_group = row["êµ¬ë¶„"].strip()
                last_group_overall = last_group
            if row["ì£¼ìš” í•­ëª©"].strip():
                last_item = row["ì£¼ìš” í•­ëª©"].strip()
            if row["ê´€ë ¨ì¡°í•­"].strip():
                last_ref = row["ê´€ë ¨ì¡°í•­"].strip()

        if rows:
            tables.append({
                "headers": CANON_HEADERS,
                "rows": rows
            })

    return tables, last_group_overall


# ------------------------------------------------------------
# 2ï¸âƒ£ í˜„ì¬ ì„¹ì…˜ì„ sections ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
# ------------------------------------------------------------
def flush_open_section(buf: Dict[str, Any], sections: List[Dict[str, Any]]):
    if not buf.get("type") or not buf.get("content_lines"):
        return
    content = "\n".join(buf["content_lines"]).strip()
    if not content:
        return

    tables, last_group = parse_markdown_table(content)
    buf["last_group"] = last_group

    if tables:
        sections.append({
            "type": "í‘œ",
            "title": buf.get("title"),
            "subtitle": buf.get("subtitle"),
            "text": None,
            "table": tables
        })
    else:
        sections.append({
            "type": buf["type"],
            "title": buf.get("title"),
            "subtitle": buf.get("subtitle"),
            "text": content,
            "table": None
        })
    buf.clear()


# ------------------------------------------------------------
# 3ï¸âƒ£ í˜ì´ì§€ ë‹¨ìœ„ Markdown íŒŒì„œ
# ------------------------------------------------------------
def parse_md_page(md_text: str, page_no: int, prev_title: Optional[str]) -> Dict[str, Any]:
    lines = md_text.splitlines()
    sections = []
    buf = {}
    current_title = None
    last_table_title = None

    # ğŸ”¹ ìµœê·¼ ë§Œë‚œ í—¤ë”©ì„ ê¸°ì–µ
    last_h2 = None
    last_h3 = None

    def start_section(sec_type, title, subtitle):
        flush_open_section(buf, sections)
        buf["type"] = sec_type
        buf["title"] = title
        buf["subtitle"] = subtitle
        buf["content_lines"] = []

    carry_title = prev_title

    for raw in lines:
        line = raw.rstrip("\n")

        # âœ… (1) â”ƒí‘œ 19â”ƒ ë¼ì¸ ì™„ì „ ì •ì œ + íƒì§€
        line_clean = re.sub(r"[#`]", "", line)
        line_clean = re.sub(r"\|+\s*---\s*\|+", "", line_clean)
        line_clean = re.sub(r"^\s*\|+\s*|\s*\|+\s*$", "", line_clean)
        line_clean = line_clean.strip()

        if re.search(r"â”ƒí‘œ\s*\d+â”ƒ", line_clean):
            clean = re.sub(r"^\s*\|?\s*", "", line_clean)
            clean = re.sub(r"\s*\|?\s*$", "", clean).strip()

            # âœ… í‘œ ì‹œì‘ ì‹œ, 'ë°”ë¡œ ì§ì „ì˜ H3'ë¥¼ subtitleë¡œ ì±„ìš´ë‹¤
            current_title = clean
            carry_title = None
            start_section("í‘œ", clean, last_h3)   # â† â˜… ì—¬ê¸°!
            last_table_title = clean
            continue

        # âœ… (2) í—¤ë” ê°ì§€
        m = RE_H.match(line)
        if m:
            hashes, text = m.groups()

            # í—¤ë” í…ìŠ¤íŠ¸ ë‚´ 'â”ƒí‘œ nâ”ƒ' ê°ì§€ â†’ ê°•ì œ í‘œ ì„¹ì…˜
            if re.search(r"â”ƒí‘œ\s*\d+â”ƒ", text):
                clean = re.sub(r"^\s*#+\s*\|?\s*", "", text)
                clean = re.sub(r"\s*\|?\s*$", "", clean).strip()
                # ìµœê·¼ H3ë¥¼ subtitleë¡œ ì‚¬ìš©
                flush_open_section(buf, sections)
                start_section("í‘œ", clean, last_h3)  # â† â˜… ì—¬ê¸°!
                last_table_title = clean
                continue

            # í—¤ë” ë ˆë²¨ë³„ ì²˜ë¦¬
            if len(hashes) == 2:  # ## H2
                last_h2 = text
                # ê¸°ì¡´ ë¡œì§ ìœ ì§€: í‘œ ì œëª© ì§í›„ì— H2ê°€ ë‚˜ì˜¤ë©´ ê·¸ê±¸ subtitleë¡œ
                if last_table_title:
                    # ì§ì „ í‘œ ì„¹ì…˜ì´ ì•„ì§ ë²„í¼ì— ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë²„í¼ ìƒíƒœ ë°˜ì˜
                    if buf.get("type") == "í‘œ" and buf.get("subtitle") in (None, "") and buf.get("title") == last_table_title:
                        buf["subtitle"] = text
                        last_table_title = None
                        # ì´ì–´ì§€ëŠ” ë‚´ìš©ì´ í‘œ ë³¸ë¬¸ì´ ì•„ë‹ ìˆ˜ ìˆì–´ í•´ì„¤ ì‹œì‘
                        start_section("í•´ì„¤", current_title, None)
                    else:
                        start_section("í‘œ", last_table_title, text)
                        last_table_title = None
                else:
                    current_title = text
                    start_section("í•´ì„¤", current_title, None)
                continue

            elif len(hashes) == 3:  # ### H3
                last_h3 = text

                # ğŸ”¥ ë³´ì •: ë°©ê¸ˆ ì „ ë§Œë“  "í‘œ" ì„¹ì…˜ì— subtitleì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ H3ë¥¼ ë¶™ì—¬ì¤€ë‹¤
                if sections and sections[-1].get("type") == "í‘œ" and not sections[-1].get("subtitle"):
                    sections[-1]["subtitle"] = text
                    # ì´ H3ëŠ” í‘œì˜ ë¶€ì œì˜€ìœ¼ë‹ˆ ë³„ë„ í•´ì„¤ ì„¹ì…˜ì€ ì‹œì‘í•˜ì§€ ì•Šê³  ë‹¤ìŒ ì¤„ ì²˜ë¦¬
                    continue

                # ì¼ë°˜ í•´ì„¤ ì„¹ì…˜ ì‹œì‘
                start_section("í•´ì„¤", current_title or carry_title, text)
                continue

        # âœ… (3) ê¸°ë³¸ í•´ì„¤ ë¼ì¸
        if not buf.get("type"):
            start_section("í•´ì„¤", current_title or carry_title, None)

        buf.setdefault("content_lines", []).append(line)

    flush_open_section(buf, sections)

    # ... ì´í•˜ ë™ì¼ (last_group íƒìƒ‰/ë¦¬í„´ë¶€ ìœ ì§€)

    # âœ… ë§ˆì§€ë§‰ êµ¬ë¶„ carry
    last_group = None
    for sec in reversed(sections):
        if sec.get("type") == "í‘œ" and sec.get("table"):
            for t in reversed(sec["table"]):
                for r in reversed(t["rows"]):
                    if r.get("êµ¬ë¶„") and r["êµ¬ë¶„"].strip():
                        last_group = r["êµ¬ë¶„"].strip()
                        break
                if last_group:
                    break
        if last_group:
            break

    return {
        "page_no": str(page_no),
        "sections": sections,
        "last_article_title": current_title or prev_title,
        "last_group": last_group,
        "last_h3": last_h3     # âœ… ì¶”ê°€
    }


# ------------------------------------------------------------
# 4ï¸âƒ£ íŒŒì¼ ë¡œë“œ ë° í˜ì´ì§€ carry ì²˜ë¦¬
# ------------------------------------------------------------
def load_pages(md_dir: Path, glob_pat: str) -> List[Path]:
    return sorted(md_dir.glob(glob_pat), key=lambda p: int(re.search(r"(\d+)", p.stem).group(1)))


def main():
    page_files = load_pages(MD_DIR, PAGE_GLOB)
    flat_sections = []
    prev_title = None
    prev_group = None
    prev_h3 = None

    for p in page_files:
        m = re.search(r"(\d+)", p.stem)
        page_no = int(m.group(1)) if m else -1
        if not (PAGE_START <= page_no <= PAGE_END):
            continue

        md_text = p.read_text(encoding="utf-8", errors="ignore")
        parsed = parse_md_page(md_text, page_no, prev_title)
        prev_title = parsed["last_article_title"]
        if parsed.get("last_h3"):
            prev_h3 = parsed["last_h3"]

        for sec in parsed["sections"]:
                # âœ… subtitle ë³´ì •
            if sec["type"] == "í‘œ" and not sec.get("subtitle"):
                if prev_h3:
                    sec["subtitle"] = prev_h3
            if sec["type"] == "í‘œ" and sec.get("table"):
                for t in sec["table"]:
                    for r in t["rows"]:
                        # ì´ì „ í˜ì´ì§€ì˜ êµ¬ë¶„ carry
                        if not r.get("êµ¬ë¶„") or r["êµ¬ë¶„"].strip("- ") == "":
                            if prev_group:
                                r["êµ¬ë¶„"] = prev_group
                        if r.get("êµ¬ë¶„") and r["êµ¬ë¶„"].strip():
                            prev_group = r["êµ¬ë¶„"].strip()

            flat_sections.append({
                "page_no": parsed["page_no"],
                "type": sec["type"],
                "title": sec["title"],
                "subtitle": sec.get("subtitle"),
                "text": sec.get("text"),
                "table": sec.get("table")
            })

        if parsed.get("last_group"):
            prev_h3 = parsed["last_h3"]
            prev_group = parsed["last_group"]

    out = {
        "meta": {"source": str(MD_DIR), "pages": f"{PAGE_START}-{PAGE_END}"},
        "sections": flat_sections
    }

    OUT_JSON.parent.mkdir(parents=True, exist_ok=True)
    OUT_JSON.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… Saved: {OUT_JSON} (pages={PAGE_START}-{PAGE_END}, sections={len(flat_sections)})")


if __name__ == "__main__":
    main()
