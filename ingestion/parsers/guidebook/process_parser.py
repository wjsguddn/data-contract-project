# -*- coding: utf-8 -*-
"""
Markdown â†’ Semantic JSON (ì¡°/í•´ì„¤/ì†Œì œëª© + í‘œ ë§¤í•‘)
--------------------------------------------------------
- ì…ë ¥: page-*.md (Vision ëª¨ë¸ í›„ì²˜ë¦¬ëœ Markdown)
- ê·œì¹™ ê¸°ë°˜ íŒŒì„œ: LLM í˜¸ì¶œ ì—†ìŒ
- ê³„ì¸µ: # (ì¥) / ## (ì¡°) / ### (í•´ì„¤Â·ì†Œì œëª©)
- í‘œ(| ... |) ìë™ ê°ì§€ â†’ content ìœ ì§€ + table ë§¤í•‘
- ì¶œë ¥: ì§€ì • í˜ì´ì§€ ë²”ìœ„ë§Œ í¬í•¨ëœ JSON
"""

import re
import json
from pathlib import Path
from typing import List, Dict, Any, Optional

# ========= ì„¤ì • =========
MD_DIR = Path(r"C:\Users\USER\Downloads\pdf-ocr-test - ë³µì‚¬ë³¸\markitdowntext\3_md_final")  # ğŸ“‚ Markdown í´ë”
PAGE_GLOB = "page-*.md"
PAGE_START = 90 # ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸
PAGE_END   = 109
OUT_JSON = Path(r"C:\Users\USER\Downloads\pdf-ocr-test - ë³µì‚¬ë³¸\markitdowntext\parsed_90_109_table_1.json")
# ========================

RE_H = re.compile(r"^(#{1,6})\s+(.*)\s*$")
RE_ARTICLE_H2 = re.compile(r"^ì œ\s*\d+\s*ì¡°\b")
RE_ENUM_TOP = re.compile(r"^([\u2460-\u2473]|[â‘ -â‘³]|(?:\(?\d+\)|\d+\.)|[ê°€-í£]\.|[ê°€-í£]\))\s+")
RE_SUP_REF = re.compile(r"<sup>(\d+)</sup>")
RE_SUP_DEF = re.compile(r"^<sup>(\d+)</sup>\s*(.+)")


# âœ… Markdown í‘œ ë¸”ë¡(| ... |) â†’ JSON í–‰ë ¬ íŒŒì„œ
def parse_markdown_table(md_text: str) -> List[Dict[str, Any]]:
    tables = []
    pattern = re.compile(r"((?:\|.*\|\n?)+)", re.MULTILINE)
    for block in pattern.findall(md_text):
        lines = [ln.strip() for ln in block.strip().splitlines() if ln.strip()]
        if len(lines) < 2:
            continue
        headers = [h.strip() for h in lines[0].strip("|").split("|")]
        rows = []
        for row_line in lines[2:]:  # í—¤ë”+êµ¬ë¶„ì„  ì œì™¸
            cells = [c.strip() for c in row_line.strip("|").split("|")]
            if len(cells) != len(headers):
                continue
            rows.append(dict(zip(headers, cells)))
        if rows:
            tables.append({"headers": headers, "rows": rows})
    return tables


def normalize_line(s: str) -> str:
    return re.sub(r"\s+", " ", s.strip())

def is_blank(s: str) -> bool:
    return len(s.strip()) == 0

def looks_like_article_h2(text: str) -> bool:
    return bool(RE_ARTICLE_H2.search(text))


def flush_open_section(buf: Dict[str, Any], sections: List[Dict[str, Any]]):
    if buf.get("type") and buf.get("content_lines"):
        # âœ… content ì¡°ë¦½ ë° markdown code fence ì œê±°
        content = "\n".join(buf["content_lines"]).strip()
        content = re.sub(r"^```(?:markdown)?|```$", "", content, flags=re.MULTILINE).strip()
        if not content:
            return

        tables = parse_markdown_table(content)

        # âœ… í‘œ ë¶„ë¦¬ ëª¨ë“œ
        if tables:
            # âœ… ë§ˆì§€ë§‰ ì¤„ ê°œí–‰ ì—†ëŠ” í‘œê¹Œì§€ ì™„ë²½íˆ ì œê±°
            text_only = re.sub(r"((?:\|.*\|\n?)+)", "", content, flags=re.MULTILINE).strip()

            if text_only:
                sections.append({
                    "type": buf["type"],
                    "title": buf.get("title"),
                    "subtitle": buf.get("subtitle"),
                    "content": text_only,
                    "continued": bool(buf.get("continued", False)),
                    "ocr_missing": False
                })

            # âœ… í‘œë§Œ ë³„ë„ sectionìœ¼ë¡œ ì¶”ê°€
            for t in tables:
                sections.append({
                    "type": "í‘œ",
                    "title": buf.get("title"),
                    "subtitle": buf.get("subtitle"),
                    "content": None,
                    "table": [t],
                    "continued": bool(buf.get("continued", False)),
                    "ocr_missing": False
                })

        else:
            # âœ… í‘œê°€ ì—†ì„ ë•Œ ì¼ë°˜ ì„¹ì…˜ ì¶”ê°€
            sections.append({
                "type": buf["type"],
                "title": buf.get("title"),
                "subtitle": buf.get("subtitle"),
                "content": content,
                "continued": bool(buf.get("continued", False)),
                "ocr_missing": False
            })

        # âœ… footnote_refs ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ì„¹ì…˜ì— ì¶”ê°€
        if "footnote_refs" in buf:
            sections[-1]["footnote_refs"] = buf["footnote_refs"]

    buf.clear()
    
def parse_md_page(md_text: str,
                  page_no: int,
                  prev_article_title: Optional[str],
                  prev_subtitle: Optional[str] = None) -> Dict[str, Any]:
    lines = md_text.splitlines()
    sections: List[Dict[str, Any]] = []
    current_article_title = None
    carry_subtitle = prev_subtitle
    have_seen_article_this_page = False
    open_buf: Dict[str, Any] = {}

    def start_new_section(sec_type: str, title: str, subtitle: Optional[str], continued: bool):
        flush_open_section(open_buf, sections)
        open_buf["type"] = sec_type
        open_buf["title"] = title
        open_buf["subtitle"] = subtitle
        open_buf["content_lines"] = []
        open_buf["continued"] = continued
        open_buf["footnote_refs"] = []

    carry_title = prev_article_title
    first_nonblank_seen = False

    first_line = next((l for l in lines if l.strip()), "")
    if carry_title and first_line and not first_line.strip().startswith("#"):
        # ì´ì „ í˜ì´ì§€ì˜ ì¡°ë¬¸/í•´ì„¤ì´ ì´ì–´ì§€ëŠ” ê²½ìš°ë¡œ ê°„ì£¼
        start_new_section("í•´ì„¤", carry_title, carry_subtitle, True)
        open_buf["content_lines"].append(first_line)
        # ì²« ì¤„ì´ ì´ë¯¸ ì²˜ë¦¬ëìœ¼ë¯€ë¡œ ì‚­ì œ (ì¤‘ë³µ ë°©ì§€)
        lines = lines[1:]


    for raw in lines:
        line = raw.rstrip("\n")
        m = RE_H.match(line)
                # âœ… <sup>n</sup> ê°ì£¼ ì°¸ì¡° ê°ì§€
        sup_refs = RE_SUP_REF.findall(line)
        if sup_refs:
            open_buf.setdefault("footnote_refs", [])
            open_buf["footnote_refs"].extend(map(int, sup_refs))

        if not sections and not open_buf.get("type") and not line.strip().startswith("#"):
            if carry_title:  # ì´ì „ ì¡°ë¬¸/í•´ì„¤ì´ ìˆë‹¤ë©´
                start_new_section("í•´ì„¤", carry_title, carry_subtitle, True)
                open_buf["content_lines"].append(line)
                continue

        # âœ… <sup>n</sup> ê°ì£¼ ì •ì˜ ê°ì§€
        m_sup_def = RE_SUP_DEF.match(line.strip())
        if m_sup_def:
            sup_id = int(m_sup_def.group(1))
            sup_text = m_sup_def.group(2).strip()
            title_for_expl = current_article_title or carry_title
            sections.append({
                "type": "ì£¼ì„",
                "title": title_for_expl,
                "subtitle": f"ì°¸ê³ ìë£Œ {sup_id}",
                "content": sup_text,
                "continued": True
            })
            continue

        # í‘œ í•´ì„¤ ê°ì§€
        if (line.strip().startswith("- **") or line.strip().startswith("- ")) and sections:
            last_section = sections[-1]
            if last_section.get("table"):
                # ì§ì „ ì„¹ì…˜ì´ í‘œë¥¼ ê°€ì§„ ê²½ìš° â†’ ìƒˆ í•´ì„¤ ì„¹ì…˜ìœ¼ë¡œ ì „í™˜
                title_for_expl = last_section.get("title")
                subtitle = last_section.get("subtitle") or "í‘œ í•´ì„¤"
                start_new_section("í•´ì„¤", title_for_expl, subtitle, True)
                open_buf["content_lines"].append(line)
                continue

        # âœ… í—¤ë”ê°€ ì•„ë‹Œ ì¼ë°˜ ì¤„ì—ì„œë„ <ì˜ˆì‹œ ë¬¸êµ¬> ê°ì§€
        if re.search(r"<\s*ì˜ˆì‹œ\s*ë¬¸êµ¬\s*\d*\s*>", line.strip()):
            title_for_expl = current_article_title or carry_title
            subtitle = line.strip().replace("<", "").replace(">", "").strip()
            start_new_section("í•´ì„¤", title_for_expl, subtitle, False)
            continue

        if m:
            hashes, text = m.group(1), m.group(2).strip()

            if len(hashes) == 2:  # ## ì¡°ë¬¸
                if looks_like_article_h2(text):
                    # ì œnì¡°ë©´ ì¡°ë¬¸ìœ¼ë¡œ ì‹œì‘
                    current_article_title = text
                    have_seen_article_this_page = True
                    start_new_section("ì¡°", current_article_title, None, False)
                    continue

                # âœ… "## 02 ë°ì´í„° ì œê³µí˜• í•´ì„¤" â†’ ì´ì „ í•´ì„¤ì˜ ì—°ì†ìœ¼ë¡œ ê°„ì£¼ (subtitle ìœ ì§€)
                if re.match(r"^\d{1,2}\.?\s*ë°ì´í„°\s*(ì œê³µí˜•|ê°€ê³µí˜•|ì¤‘ê°œí˜•)\s*í•´ì„¤", text):
                    title_for_expl = carry_title or current_article_title
                    subtitle = carry_subtitle  # âœ… ìƒˆë¡œ ê°±ì‹ í•˜ì§€ ì•Šê³  ì´ì „ subtitle ìœ ì§€
                    start_new_section("í•´ì„¤", title_for_expl, subtitle, True)
                    continue

                elif re.search(r"<\s*ì˜ˆì‹œ\s*ë¬¸êµ¬\s*\d*", text):
                    # âœ… ì˜ˆì‹œ ë¬¸êµ¬ â†’ ë³„ë„ í•´ì„¤ ë¸”ë¡ìœ¼ë¡œ ì²˜ë¦¬
                    subtitle = text.replace("<", "").replace(">", "").strip()
                    title_for_expl = current_article_title or carry_title
                    start_new_section("í•´ì„¤", title_for_expl, subtitle, False)
                    continue

                else:
                    # âœ… NEW: ì¼ë°˜ í•´ì„¤ í—¤ë” ì²˜ë¦¬ (ex: ## ìš©ì–´ì˜ ì •ì˜)
                    # carry_titleê³¼ textê°€ ëª¨ë‘ 'ì •ì˜', 'ìš©ì–´' í¬í•¨ì´ë©´ ì´ì „ ì¡°ë¬¸ í•´ì„¤ì˜ ì—°ì†ìœ¼ë¡œ ê°„ì£¼
                    if carry_title and re.search(r"(ì •ì˜|ìš©ì–´)", carry_title) and re.search(r"(ì •ì˜|ìš©ì–´)", text):
                        title_for_expl = carry_title
                        start_new_section("í•´ì„¤", title_for_expl, text, True)
                    else:
                        # ì™„ì „íˆ ìƒˆë¡œìš´ í•´ì„¤ ëŒ€ì£¼ì œ
                        current_topic_title = text
                        start_new_section("í•´ì„¤", current_topic_title, None, False)
                    continue


            elif len(hashes) == 3:  # ### í•´ì„¤
                subtitle = text
                title_for_expl = current_article_title or carry_title
                cont = not have_seen_article_this_page and bool(title_for_expl)
                start_new_section("í•´ì„¤", title_for_expl, subtitle, cont)
                continue
            elif len(hashes) == 4:
                if RE_ARTICLE_H2.search(text):
                    # ê¸°ì¡´ ì¡°ë¬¸ fallback
                    current_article_title = text
                    have_seen_article_this_page = True
                    start_new_section("ì¡°", current_article_title, None, False)
                else:
                    # âœ… NEW: '###' í•´ì„¤ ë°‘ì˜ '####'ë¥¼ ì†Œì œëª©ìœ¼ë¡œ ì¸ì‹
                    subtitle = text
                    title_for_expl = current_article_title or carry_title
                    start_new_section("í•´ì„¤", title_for_expl, subtitle, False)
                continue

            else:
                flush_open_section(open_buf, sections)
                continue
            
        # âœ… NEW: ê°ì£¼í˜• ë²•ë ¹ ë¸”ë¡ ê°ì§€ ([^11]: ã€Œë°ì´í„°ì‚°ì—…ë²•ã€ ì œ12ì¡° ...)
        m_foot = re.match(r"\[\^(\d+)\]:\s*(.+)", line.strip())
        if m_foot:
            foot_num = m_foot.group(1)
            rest_text = m_foot.group(2)
            m_law = re.search(r"ã€Œ([^ã€]{3,})ë²•ã€", rest_text)
            law_name = m_law.group(1).strip() + "ë²•" if m_law else f"ë²•ë ¹ê°ì£¼{foot_num}"
            title_for_expl = current_article_title or carry_title

            start_new_section("ë²•ë ¹", title_for_expl, law_name, True)
            open_buf["content_lines"].append(rest_text)
            continue


        # êµµì€ í…ìŠ¤íŠ¸(**...**) â†’ í•´ì„¤ subtitle
        bold_match = re.match(r"^\*\*(.+?)\*\*", line.strip())
        if bold_match:
            subtitle = bold_match.group(1).strip()
            title_for_expl = current_article_title or carry_title
            start_new_section("í•´ì„¤", title_for_expl, subtitle, False)
            continue
        

        if not first_nonblank_seen and carry_title:
            first_line = next((l for l in lines if l.strip()), "")
            # ë§Œì•½ ì²« ì¤„ì´ "02", "ë°ì´í„° ì œê³µí˜•", "í•´ì„¤" ë“±ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì´ì „ í•´ì„¤ì˜ ì—°ì†ìœ¼ë¡œ ê°„ì£¼
            if re.match(r"^(0?\d{1,2}|ë°ì´í„°|ì´ìš©ì|ì œê³µì|í•´ì„¤)", first_line.strip()):
                title_for_expl = carry_title
                subtitle_for_expl = carry_subtitle
                start_new_section("í•´ì„¤", title_for_expl, subtitle_for_expl, True)

                        
        # âœ… ë²•ë ¹ ì¸ìš© ê°ì§€ (ë‹¨, í˜„ì¬ ì¡°ë¬¸ ë‚´ë¶€ì—ì„œëŠ” í•´ì„¤ë¡œ ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
        if re.search(r"ã€Œ[^ã€]{3,}ë²•ã€", line) and sections:
            last_section = sections[-1]
            # âš ï¸ í˜„ì¬ open_bufê°€ 'ì¡°'ë©´ í•´ì„¤ë¡œ ì „í™˜í•˜ì§€ ë§ê³  ê·¸ëƒ¥ ë³¸ë¬¸ìœ¼ë¡œ ì¶”ê°€
            if open_buf.get("type") == "ì¡°":
                open_buf["content_lines"].append(line)
                continue

            # âœ… ì¡°ë¬¸ì´ ì•„ë‹Œ ê²½ìš°(í•´ì„¤ ë“±)ì—ì„œë§Œ ìƒˆ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬
            title_for_expl = last_section.get("title") or carry_title
            subtitle = "ê´€ë ¨ ë²•ë ¹ í•´ì„¤"
            start_new_section("í•´ì„¤", title_for_expl, subtitle, True)
            open_buf["content_lines"].append(line)
            continue

        if not open_buf.get("type"):
            if RE_ENUM_TOP.match(line) and (current_article_title or carry_title):
                if not current_article_title:
                    current_article_title = carry_title
                start_new_section("ì¡°", current_article_title, None, True)
            else:
                continue

        if is_blank(line):
            if open_buf["content_lines"] and open_buf["content_lines"][-1] != "":
                open_buf["content_lines"].append("")
        else:
            open_buf["content_lines"].append(line)

    flush_open_section(open_buf, sections)

    last_subtitle_val = None
    if sections:
        for sec in reversed(sections):
            if sec.get("subtitle"):
                last_subtitle_val = sec["subtitle"]
                break

    return {
        "page_no": str(page_no),
        "sections": sections,
        "last_article_title": current_article_title or prev_article_title,
        "last_subtitle": last_subtitle_val,
    }



def load_pages(md_dir: Path, glob_pat: str) -> List[Path]:
    pages = sorted(md_dir.glob(glob_pat),
                   key=lambda p: int(re.search(r"(\d+)", p.stem).group(1)))
    return pages


def main():
    page_files = load_pages(MD_DIR, PAGE_GLOB)
    all_pages: List[Dict[str, Any]] = []
    flat_sections: List[Dict[str, Any]] = []

    prev_title: Optional[str] = None
    prev_subtitle: Optional[str] = None
    for p in page_files:
        m = re.search(r"(\d+)", p.stem)
        page_no = int(m.group(1)) if m else -1
        if not (PAGE_START <= page_no <= PAGE_END):
            continue


        md_text = p.read_text(encoding="utf-8", errors="ignore")
        parsed = parse_md_page(md_text, page_no, prev_title, prev_subtitle)
        prev_title = parsed["last_article_title"]
        prev_subtitle = parsed.get("last_subtitle")
        
        

        all_pages.append({"page_no": parsed["page_no"], "sections": parsed["sections"]})
        for sec in parsed["sections"]:
            flat_sections.append({
                "page_no": parsed["page_no"],
                "type": sec["type"],
                "title": sec["title"],
                "subtitle": sec.get("subtitle"),
                "text": sec["content"],
                "table": sec.get("table")  # âœ… í‘œ í¬í•¨
            })

    out = {
        "meta": {"source": str(MD_DIR), "pages": f"{PAGE_START}-{PAGE_END}"},
        "sections": flat_sections
    }
    OUT_JSON.parent.mkdir(parents=True, exist_ok=True)
    OUT_JSON.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… Saved: {OUT_JSON} (pages={PAGE_START}-{PAGE_END}, sections={len(flat_sections)})")

if __name__ == "__main__":
    main()
